{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Arnaud_Watusadisi_Mavakala_AMMI_DL_Assignment_TorchNN1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAkBSdTvq0Cr"
      },
      "source": [
        "<img src='http://sn.nexteinstein.org/wp-content/uploads/sites/12/2016/07/aims_senegal.jpg' />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSBZZYqgq2Su"
      },
      "source": [
        "In this notebook you will implement and train a feed-forward neural network using the torch.nn module to solve a multi-class classification problem on a dataset called \"Fashion MNIST\".\n",
        "\n",
        "---\n",
        "\n",
        "***Learning Objectives:***\n",
        "\n",
        "* Understand how to use Pytorch nn module and the sequential container to build a neural network architecture.\n",
        "\n",
        "\n",
        "* Understand how a model is trained using the opitm module and the Autgrad engine and How to evaluate your model.\n",
        "\n",
        "---\n",
        "\n",
        "**Resources that you need to cover before starting**:\n",
        "\n",
        "* Review the Tutorial Notebook.\n",
        "\n",
        "* Read the torch.nn docs: https://pytorch.org/docs/stable/nn.html\n",
        "\n",
        "* Read the article about moving from computing gradient from scratch to useing torch.nn https://pytorch.org/tutorials/beginner/nn_tutorial.html\n",
        "\n",
        "* Read the pytorch offical tutorial on training multi-class classifiers:\n",
        "https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4ngU0vOrd68"
      },
      "source": [
        "# Setup code (Read first But Don't modify)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NljcxD0Estne"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MygxOwpX-H4f"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQKtRDqBz3gT"
      },
      "source": [
        "#### Loading the Data: \n",
        "\n",
        "We will use the Fashion MNIST dataset consisting of 70,000 greyscale images of shape(28x28 flattened to have shape 784) and their labels.\n",
        "\n",
        "The dataset is divided into 60,000 training images and 10,000 test images. The idea is to train a classifier to identify the class value (what type of fashion item it is) given the image (total of **10** classes).\n",
        "\n",
        "We will split the training data into 50,000 training images used to train a model on it, and 10,000 validation images used to tune your choice of hyperparams and model architecture.\n",
        "\n",
        "The last step is to evaluate how well your model classifies the 10,000 test images (will be used to assess your implementation).\n",
        "\n",
        "\n",
        "**The classes are: ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']**\n",
        "\n",
        "This is how the 10 class images looks like before flattening it:\n",
        "\n",
        "<img src='https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F549262%2Fd6f4f6e13fa211c9e773479566d89ac9%2FExample-for-fashion-MNIST-Each-class-is-represented-by-nine-cases.png?generation=1576784453715625&alt=media' />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyVLHX__-Jws"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mX1jXWxtweco"
      },
      "source": [
        "#get the data\n",
        "\n",
        "def load_data():\n",
        "\n",
        "  #using the dataset module from torchvision\n",
        "  mnist_train_set = datasets.FashionMNIST('data/fashiomnist/', train = True, download = True)\n",
        "  mnist_test_set = datasets.FashionMNIST('data/fashiomnist/', train = False, download = True)\n",
        "\n",
        "  #train data\n",
        "  train_images = mnist_train_set.data.view(-1, 1, 28, 28).float()\n",
        "  train_targets = mnist_train_set.targets\n",
        "\n",
        "  #test data\n",
        "  test_images = mnist_test_set.data.view(-1, 1, 28, 28).float()\n",
        "  y_test = mnist_test_set.targets\n",
        "\n",
        "  #flatten\n",
        "  train_val_input = train_images.clone().reshape(train_images.size(0), -1)/255.0\n",
        "  x_test = test_images.clone().reshape(test_images.size(0), -1)/255.0\n",
        "\n",
        "  # shuffle\n",
        "  N = train_val_input.shape[0]\n",
        "  index = torch.randperm(N)\n",
        "\n",
        "  #train val split\n",
        "  x_train = train_val_input[index][:50000]\n",
        "  y_train = train_targets[index][:50000]\n",
        "\n",
        "  x_val = train_val_input[index][50000:]\n",
        "  y_val = train_targets[index][50000:]\n",
        "\n",
        "  return x_train, y_train, x_val, y_val, x_test, y_test"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmO0FsLnYxpJ"
      },
      "source": [
        "x_train, y_train, x_val, y_val, _, __ = load_data()"
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHajRlnh8ZBe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2043aa6-d79f-457c-f644-2fe77f777aad"
      },
      "source": [
        "print('train data shape: ', x_train.shape)\n",
        "print('train targets shape: ', y_train.shape)\n",
        "print(' ')\n",
        "print('validation data shape: ', x_val.shape)\n",
        "print('Validation targets shape: ', y_val.shape)"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train data shape:  torch.Size([50000, 784])\n",
            "train targets shape:  torch.Size([50000])\n",
            " \n",
            "validation data shape:  torch.Size([10000, 784])\n",
            "Validation targets shape:  torch.Size([10000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qVF8ZdO-MkE"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpfIjcho6PIV"
      },
      "source": [
        "#### We will be using gpus to accelerate the training. make sure to change your runtime to use a *gpu*.\n",
        "\n",
        "#### go to Runtime ===> Change Runtime Type ===> Hardware accelerator ===> choose (GPU)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GA5llWY9te4E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69c740ab-cc22-41e5-8707-6a46c01ac782"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "  device = torch.device('cuda:0')\n",
        "else:\n",
        "  device = torch.device('cpu')\n",
        "  \n",
        "print('using device:', device)"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "using device: cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZgAMtBSZHqA"
      },
      "source": [
        "Note that every tensor in pytorch has a **.device** attribute By default it's set to 'cpu' But it can be changed to 'gpu' using the **'.to'** command:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "La4h7iZnZbiR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5b58a6d-3d41-46ed-ea3e-57f081a8767e"
      },
      "source": [
        "# toy example \n",
        "a = torch.rand(2,3)\n",
        "print(a.device) # by default it's 'cpu'\n",
        "\n",
        "a = a.to(device = device)\n",
        "print(a.device) # should print 'cuda:0'"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cpu\n",
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NN2tXNtr9-vX"
      },
      "source": [
        "---\n",
        "---\n",
        "---\n",
        "---\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zk-ExNrjaAU5"
      },
      "source": [
        "Now it's your turn to define a model using the **torch.nn.Sequential** container module.\n",
        "\n",
        "Your model should accept an input of shape D = 784 and output 10 numbers represent the probability of belonging to each class.\n",
        "\n",
        "ideally a good model will have at least one hidden layer (or more) followed by non-linear activation functions like (nn.ReLU, nn.Sigmoid ... etc) \n",
        "\n",
        "\n",
        "you can take some help from the docs: \n",
        "https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IqWt4DHtf_O"
      },
      "source": [
        "# define a neural network model using the nn.Sequential container\n",
        "\n",
        "D = x_train.shape[1]\n",
        "n_classes = 10\n",
        "\n",
        "model = nn.Sequential(nn.Linear(784, 400),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(400, 200),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(200, 100),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(100, 10),\n",
        "                      nn.LogSoftmax(dim = 1) \n",
        "                     )"
      ],
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7-cOz-vcKM0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1526504c-fb88-49cb-e54e-5f5a56e102b4"
      },
      "source": [
        "print(model) #Run this when you finish defining your model"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=784, out_features=400, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): Linear(in_features=400, out_features=200, bias=True)\n",
            "  (3): ReLU()\n",
            "  (4): Linear(in_features=200, out_features=100, bias=True)\n",
            "  (5): ReLU()\n",
            "  (6): Linear(in_features=100, out_features=10, bias=True)\n",
            "  (7): LogSoftmax(dim=1)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4NkC5mRb-go"
      },
      "source": [
        "#Run This cell\n",
        "# it's important to transfer your model to the gpu for faster computations\n",
        "\n",
        "model = model.to(device=device)"
      ],
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0hV6tQTcVNt"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snZysKgKcekB"
      },
      "source": [
        "Now that we have our model and data ready, we need to train it: \n",
        "\n",
        "But in order to do that we need to define our loss function:\n",
        "\n",
        "luckly pytorch has most loss functions already implemented, for multi-class classification problems, we will be using the cross entroy loss which is basically computing the log softmax of an input followed by computing the negative log liklihood loss.\n",
        "\n",
        "read this for more info on the cross entropy loss: https://en.wikipedia.org/wiki/Cross_entropy\n",
        "\n",
        "also check the pytorch definition of it: https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html (**important**)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lM_r6ITEwfov"
      },
      "source": [
        "#run this cell\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVQiq0zveZQj"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ce7Wdomjejk9"
      },
      "source": [
        "Another important step in training any model is to update it's weights and biases, and for that we need an optimization algorithm like Gradient decsent, Luckily in pytorch most optimization algorithms are implemented in the torch.optim module, and for this assignment we will be using the optim.SGD But you are free to look into more optim in the doc: https://pytorch.org/docs/stable/optim.html.\n",
        "\n",
        "You need to find suitable values for the learning rate and the momentum value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73N2vqTWd_iC"
      },
      "source": [
        "learning_rate = 0.01        # to be set\n",
        "momentum_value = 0.9       # to be set\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr = learning_rate, momentum = momentum_value)"
      ],
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Io1LkA5Ufzpp"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0Q9c1eaf3IY"
      },
      "source": [
        "# Now that we have all things set, let's train our model using Automatic differentaition from pytorch. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIUCO2XAwfr2"
      },
      "source": [
        "batch_size = 100        #set your batch size "
      ],
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUa8WLW1gO8k"
      },
      "source": [
        "#Run this cell \n",
        "# it wil set the number of batches for mini batch SGD\n",
        "\n",
        "N = x_train.shape[0]\n",
        "\n",
        "if N % batch_size == 0:\n",
        "  n_batches = int(N / batch_size)\n",
        "else:\n",
        "  n_batches = int(N / batch_size) + 1"
      ],
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARNONOwUguAl"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1MbG4fFgwBy"
      },
      "source": [
        "# Main Training loop\n",
        "### ToDo: fill in the missing steps\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5Gd17hRwfvA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "423e2061-7de6-4b71-8507-b32f3626d479"
      },
      "source": [
        "n_epochs = 50    # set the number of epochs\n",
        "losses = []\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "  \n",
        "  epoch_loss = 0\n",
        "  \n",
        "  for batch in range(n_batches):\n",
        "    \n",
        "    start = batch * batch_size\n",
        "    end = start + batch_size\n",
        "\n",
        "    train_images = x_train[start:end]\n",
        "    train_labels = y_train[start:end]\n",
        "\n",
        "    train_images =  train_images.to(device = device)        # change the device of train_images to gpu\n",
        "    train_labels =  train_labels.to(device = device)     # change the device of train_labels to gpu\n",
        "\n",
        "    outputs = model(train_images)     # feed the images totrain_labels the model to get the outputs\n",
        "\n",
        "    loss = criterion(outputs, train_labels)    # compute the loss using the criterion we defined\n",
        "    \n",
        "    epoch_loss += loss.item()\n",
        "    \n",
        "    \n",
        "    # zero the grad\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    # compute the gradient for each weight/bias from the loss\n",
        "    \n",
        "    loss.backward()\n",
        "\n",
        "    # update the model parameters\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "  epoch_loss = epoch_loss/N\n",
        "\n",
        "  print('epoch ==> ', epoch, 'loss ==> ', epoch_loss)\n",
        "\n",
        "  losses.append(epoch_loss)"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch ==>  0 loss ==>  0.00984752156496048\n",
            "epoch ==>  1 loss ==>  0.004943955385088921\n",
            "epoch ==>  2 loss ==>  0.004234436528086662\n",
            "epoch ==>  3 loss ==>  0.0038532856065034865\n",
            "epoch ==>  4 loss ==>  0.0035665472903847694\n",
            "epoch ==>  5 loss ==>  0.0033520671704411506\n",
            "epoch ==>  6 loss ==>  0.003177608252167702\n",
            "epoch ==>  7 loss ==>  0.003029059186279774\n",
            "epoch ==>  8 loss ==>  0.002894787285029888\n",
            "epoch ==>  9 loss ==>  0.0027772365556657315\n",
            "epoch ==>  10 loss ==>  0.0026732316270470617\n",
            "epoch ==>  11 loss ==>  0.0025799814553558826\n",
            "epoch ==>  12 loss ==>  0.002483317808806896\n",
            "epoch ==>  13 loss ==>  0.002397651594877243\n",
            "epoch ==>  14 loss ==>  0.002318080852031708\n",
            "epoch ==>  15 loss ==>  0.00224167333483696\n",
            "epoch ==>  16 loss ==>  0.002174585336446762\n",
            "epoch ==>  17 loss ==>  0.0021166123987734317\n",
            "epoch ==>  18 loss ==>  0.00208981526941061\n",
            "epoch ==>  19 loss ==>  0.0020142695105075836\n",
            "epoch ==>  20 loss ==>  0.0019679542341828346\n",
            "epoch ==>  21 loss ==>  0.001899403441399336\n",
            "epoch ==>  22 loss ==>  0.0018556175545603037\n",
            "epoch ==>  23 loss ==>  0.0017918376022577286\n",
            "epoch ==>  24 loss ==>  0.0017454930496960878\n",
            "epoch ==>  25 loss ==>  0.001668346855416894\n",
            "epoch ==>  26 loss ==>  0.0016179683689028024\n",
            "epoch ==>  27 loss ==>  0.0015761884967237711\n",
            "epoch ==>  28 loss ==>  0.0015206130758672952\n",
            "epoch ==>  29 loss ==>  0.0014890686669945716\n",
            "epoch ==>  30 loss ==>  0.0014401697424054145\n",
            "epoch ==>  31 loss ==>  0.001440130043104291\n",
            "epoch ==>  32 loss ==>  0.0014395690830796956\n",
            "epoch ==>  33 loss ==>  0.0014130736653134228\n",
            "epoch ==>  34 loss ==>  0.001379715033620596\n",
            "epoch ==>  35 loss ==>  0.0013140915512666106\n",
            "epoch ==>  36 loss ==>  0.0012802941279113293\n",
            "epoch ==>  37 loss ==>  0.001235034978017211\n",
            "epoch ==>  38 loss ==>  0.0012421784176677466\n",
            "epoch ==>  39 loss ==>  0.0012249932973086835\n",
            "epoch ==>  40 loss ==>  0.0011441082680225371\n",
            "epoch ==>  41 loss ==>  0.0011410932222381234\n",
            "epoch ==>  42 loss ==>  0.00108620918340981\n",
            "epoch ==>  43 loss ==>  0.001110329324156046\n",
            "epoch ==>  44 loss ==>  0.001093340802974999\n",
            "epoch ==>  45 loss ==>  0.0010256066652014851\n",
            "epoch ==>  46 loss ==>  0.000987616020515561\n",
            "epoch ==>  47 loss ==>  0.0009745646903477609\n",
            "epoch ==>  48 loss ==>  0.0009255671587586403\n",
            "epoch ==>  49 loss ==>  0.0009074227061122656\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjV6Vvdwh7YL"
      },
      "source": [
        "## ToDo: use matplot lib to plot the loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8RV3mWbicLV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "c816e22b-40c8-4ec0-d120-ad74f8c4e089"
      },
      "source": [
        "# Your code should ne here\n",
        "plt.plot(losses)\n",
        "plt.title(\"Training Error\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.show()"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxc1X338c9PM5LG0mixNm+ykRdhMGscY5ZAAiFpTNoEShKWhpS2NHSBkjRp2tDn9TRtnvLkSV9p0qRAGwokZGELCambkEDYIQnGMhhjG4x3LFm2JcvWZkuypN/zx72Sx0Lb2BqNpPm+X6956c65986cmwh/dc659xxzd0REREYrK90VEBGRyUXBISIiSVFwiIhIUhQcIiKSFAWHiIgkRcEhIiJJUXCIjJKZ/cLMrh/rY0UmG9NzHDKVmVlbwts8oBPoCd//mbv/cPxrdfzM7GLgaeDQgF0fdPffjn+NJBNF010BkVRy93jftpntAP7U3Z8ceJyZRd29ezzrdgJ2u3vlSAeZmRH8cdibUJbUdU6y/11knKirSjKSmV1sZrVm9ndmtgf4jplNN7OfmVmDmR0ItysTznnWzP403P4jM3vRzL4WHrvdzC47zmPnm9nzZtZqZk+a2R1m9oPjvK5nzew2M/s1QatkgZm5md1kZpuBzeFxnzazLWbWZGYrzWx2wme843iRRAoOyWQzgRLgJOBGgv8evhO+nwccBm4f5vxzgU1AGfAvwD3hX/nJHns/8DJQCvwj8KnjvqLApwiupwDYGZZdEdZhiZm9H/gKcBUwKzzmwQGf0X/8CdZFpiB1VUkm6wW+5O6d4fvDwI/7dprZbcAzw5y/093/Kzz2PuBOYAawZ7THmlkOcA5wqbt3AS+a2coR6j3bzA4OKJvj7u3h9nfdfUPCdQB8xd2bwvefBO5191fC97cCB8ysyt13hKf1Hy8ykFockska3L2j742Z5ZnZt81sp5m1AM8DxWYWGeL8/oBw977B6niSx84GmhLKAHaNUO/d7l484NWesH+w8xPLZnO0JYK7twH7gTlJ1EEymIJDMtnAWwo/DywGznX3QuC9YflQ3U9joR4oMbO8hLK5J/iZg90qmVi2m6A7DgAzyyfoJqsb4TNEAAWHSKICgu6qg2ZWAnwp1V/o7juBGuAfzSzHzM4HPpLir30A+GMzO9vMcoH/C6xK6KYSGZaCQ+SofwOmAY3AS8Avx+l7PwmcT9Bd9M/AQwTPmwxltpm1DXh9bLRfFt6O/L8JxnPqgYXANcdde8k4egBQZIIxs4eAN9095S0ekeOhFodImpnZOWa20MyyzGwFcDnw03TXS2Qouh1XJP1mAj8hGKCuBf7C3V9Nb5VEhqauKhERSYq6qkREJCkZ0VVVVlbmVVVV6a6GiMiksWbNmkZ3Lx9sX0YER1VVFTU1NemuhojIpGFmO4fap64qERFJioJDRESSktLgMLMVZrYpnPf/i4PszzWzh8L9q8ysKiwvNbNnwidibx9wzrvN7PXwnG8NM421iIikQMqCI5xR9A7gMoI5/a81s4Fz+98AHHD3RcA3gK+G5R0EUyL8zSAf/R/Ap4Hq8LVi7GsvIiJDSWWLYzmwxd23hesMPEjwRGyiy4H7wu1HgEvNzNy93d1fJAiQfmY2Cyh095c8eADlewQLzoiIyDhJZXDM4dg5/Ws5dr7/Y44J1zVuJnh6drjPrB3hMwEwsxvNrMbMahoaGpKsuoiIDGXKDo67+13uvszdl5WXD3orsoiIHIdUBkcdxy5IU8mxC8Ucc4yZRYEigqmlh/vMyhE+c8x866nNPPeWWisiIolSGRyrgWozmx+uq3wNMHAt5ZXA9eH2x4GnfZjJs9y9Hmgxs/PCu6n+EPjvsa964NvPbeW5TQoOEZFEKXty3N27zexm4HEgAtzr7hvM7MtAjbuvBO4Bvm9mW4AmEhaTMbMdQCGQY2ZXAL/j7huBvwS+S7Dgzi/CV0oUxLJp7TiSqo8XEZmUUjrliLs/Bjw2oOwfErY7gE8McW7VEOU1wOljV8uhFcSitHZ0j8dXiYhMGlN2cHwsxGNR2joVHCIiiRQcw1BXlYjIOyk4hlEQi9KqFoeIyDEUHMMoyNUYh4jIQAqOYQSD4+qqEhFJpOAYRkEsm44jvRzp6U13VUREJgwFxzDiucHdym3qrhIR6afgGEZBLAgOjXOIiByl4BhGQSwbgNZOjXOIiPRRcAxDLQ4RkXdScAxDwSEi8k4KjmH0dVW1qatKRKSfgmMYfXdVqcUhInKUgmMY6qoSEXknBccwYtkRciJZCg4RkQQKjhHENe2IiMgxFBwj0GJOIiLHUnCMoECLOYmIHEPBMYJ4rrqqREQSKThGEKwCqBaHiEgfBccINMYhInIsBccICtRVJSJyDAXHCApi2bR1duPu6a6KiMiEoOAYQUEsSq/Doa6edFdFRGRCUHCMIK5pR0REjqHgGEH/Yk4a5xARARQcI+qf6FAPAYqIAAqOERWqq0pE5BgKjhHEc9VVJSKSSMExgr6uqja1OEREAAXHiLSYk4jIsRQcI8jPiWKmrioRkT4KjhFkZRnxnKjuqhIRCSk4RkETHYqIHKXgGAUtHysiclRKg8PMVpjZJjPbYmZfHGR/rpk9FO5fZWZVCftuDcs3mdmHEsr/2sw2mNl6M3vAzGKpvAY4OtGhiIikMDjMLALcAVwGLAGuNbMlAw67ATjg7ouAbwBfDc9dAlwDnAasAO40s4iZzQFuAZa5++lAJDwupdRVJSJyVCpbHMuBLe6+zd27gAeBywccczlwX7j9CHCpmVlY/qC7d7r7dmBL+HkAUWCamUWBPGB3Cq8B6Fs+VsEhIgKpDY45wK6E97Vh2aDHuHs30AyUDnWuu9cBXwPeBuqBZnd/YrAvN7MbzazGzGoaGhpO6EK0fKyIyFGTanDczKYTtEbmA7OBfDO7brBj3f0ud1/m7svKy8tP6HsLNTguItIvlcFRB8xNeF8Zlg16TNj1VATsH+bcDwDb3b3B3Y8APwEuSEntE8Rzo3R299LV3ZvqrxIRmfBSGRyrgWozm29mOQSD2CsHHLMSuD7c/jjwtAdrtK4ErgnvupoPVAMvE3RRnWdmeeFYyKXAGym8BiBhvirdWSUiQjRVH+zu3WZ2M/A4wd1P97r7BjP7MlDj7iuBe4Dvm9kWoInwDqnwuIeBjUA3cJO79wCrzOwR4JWw/FXgrlRdQ5/ExZxK8nNS/XUiIhNayoIDwN0fAx4bUPYPCdsdwCeGOPc24LZByr8EfGlsazo8LR8rInLUpBocTxfNkCsicpSCYxQKte64iEg/BccoxHPV4hAR6aPgGAXdVSUicpSCYxSODo6rq0pERMExCrnRCDnRLHVViYig4Bi1wphWARQRAQXHqGmiQxGRgIJjlIKp1TXGISKi4BilgliUNrU4REQUHKOlVQBFRAIKjlGK52arq0pEBAXHqBXorioREUDBMWqFsShtnd309nq6qyIiklYKjlGKx6K4Q3uXWh0iktkUHKPUt5iT5qsSkUyn4BglrckhIhJQcIzS0anVdWeViGQ2BccoHV13XC0OEclsCo5RKlRXlYgIoOAYtbiCQ0QEUHCM2tG7qjTGISKZTcExSvk5EczU4hARUXCMkpmFU6srOEQksyk4klCoxZxERBQcyQimVtcYh4hkNgVHErQmh4iIgiMp8dyo5qoSkYyn4EhCQUyLOYmIKDiSoK4qEREFR1LiWgVQRETBkYzCWDZd3b10dvekuyoiImmj4EiC1uQQEVFwJKVvTY42BYeIZDAFRxK0JoeISIqDw8xWmNkmM9tiZl8cZH+umT0U7l9lZlUJ+24NyzeZ2YcSyovN7BEze9PM3jCz81N5DYmOdlXpllwRyVwpCw4ziwB3AJcBS4BrzWzJgMNuAA64+yLgG8BXw3OXANcApwErgDvDzwP4JvBLdz8FOAt4I1XXMFD/8rG6s0pEMlgqWxzLgS3uvs3du4AHgcsHHHM5cF+4/QhwqZlZWP6gu3e6+3ZgC7DczIqA9wL3ALh7l7sfTOE1HKNQXVUiIikNjjnAroT3tWHZoMe4ezfQDJQOc+58oAH4jpm9amZ3m1n+YF9uZjeaWY2Z1TQ0NIzF9airSkSEyTc4HgWWAv/h7u8C2oF3jJ0AuPtd7r7M3ZeVl5ePyZf3LR+ru6pEJJOlMjjqgLkJ7yvDskGPMbMoUATsH+bcWqDW3VeF5Y8QBMm4yI5kEcvO0hiHiGS0VAbHaqDazOabWQ7BYPfKAcesBK4Ptz8OPO3uHpZfE951NR+oBl529z3ALjNbHJ5zKbAxhdfwDproUEQyXTRVH+zu3WZ2M/A4EAHudfcNZvZloMbdVxIMcn/fzLYATQThQnjcwwSh0A3c5O5983z8FfDDMIy2AX+cqmsYTIGWjxWRDJey4ABw98eAxwaU/UPCdgfwiSHOvQ24bZDytcCysa3p6GmGXBHJdKPqqjKzfDPLCrdPNrOPmll2aqs2MamrSkQy3WjHOJ4HYmY2B3gC+BTw3VRVaiLTKoAikulGGxzm7oeAK4E73f0TBE91Zxx1VYlIpht1cIRzQn0S+HlYFhnm+Ckr6KpScIhI5hptcHwWuBV4NLzjaQHwTOqqNXHFY0FXVW+vp7sqIiJpMaq7qtz9OeA5gHCQvNHdb0llxSaqwr6nx7u6++euEhHJJKO9q+p+MysM54VaD2w0sy+ktmoTk1YBFJFMN9quqiXu3gJcAfyCYLLBT6WsVhNYPDdoZWi+KhHJVKMNjuzwuY0rgJXufgTIyE5+zZArIplutMHxbWAHkA88b2YnAS2pqtREpq4qEcl0ox0c/xbwrYSinWZ2SWqqNLH1B4ceAhSRDDXawfEiM/t638JIZvavBK2PjFPQvwqguqpEJDONtqvqXqAVuCp8tQDfSVWlJjJ1VYlIphvt7LgL3f1jCe//yczWpqJCE9207AiRLNNdVSKSsUbb4jhsZhf2vTGz9wCHU1Olic3MiOdG1VUlIhlrtC2OPwe+Z2ZF4fsDHF25L+NookMRyWSjvavqNeAsMysM37eY2WeBdams3EQVz43qrioRyVhJrTnu7i3hE+QAn0tBfSaFomnZ7GvpSHc1RETSIqngGMDGrBaTzHtPLue12ma2NbSluyoiIuPuRIIjI6ccAfjEuyuJZBkPrd6V7qqIiIy7YYPDzFrNrGWQVyswe5zqOOFUFMb4wKkVPLKmlq7u3nRXR0RkXA0bHO5e4O6Fg7wK3H20d2RNSdcsn8f+9i6efGNvuqsiIjKuTqSrKqO9t7qcOcXTeODlt9NdFRGRcaXgOE6RLOOqZXN5YXMju5oOpbs6IiLjRsFxAq46p5IsQ4PkIpJRFBwnYFbRNC5eXMHDNbvo7tEguYhkBgXHCbp2+Tz2tXby9Jv70l0VEZFxoeA4QZcsLmdGYS4PqrtKRDKEguMERSNZfOLdc3l20z52H8zICYNFJMMoOMbA1efMxYGHa9TqEJGpT8ExBuaW5HHhojIeXr2Lnt6MnYlFRDKEgmOMXLt8HrubO3j+rYZ0V0VEJKUUHGPkA6fOoCyew/16klxEpjgFxxjJiWZx9TlzefKNvby4uTHd1RERSRkFxxi6+ZJqFpbH+exDa2lo7Ux3dUREUiKlwWFmK8xsk5ltMbMvDrI/18weCvevMrOqhH23huWbzOxDA86LmNmrZvazVNY/WdNyItzxB0tp7TjC5x5eS68GykVkCkpZcJhZBLgDuAxYAlxrZksGHHYDcMDdFwHfAL4anrsEuAY4DVgB3Bl+Xp/PAG+kqu4nYvHMAr70kdN4YXMj335+W7qrIyIy5lLZ4lgObHH3be7eBTwIXD7gmMuB+8LtR4BLzczC8gfdvdPdtwNbws/DzCqB3wXuTmHdT8i1y+fyu2fO4mtPbGLNzgPpro6IyJhKZXDMARKfiKsNywY9xt27gWagdIRz/w34W2DCzipoZnzlyjOYXRzjlgdepfnQkXRXSURkzEyqwXEz+z1gn7uvGcWxN5pZjZnVNDSM/7MVhbFs/v3apext6eBvf/wa7hrvEJGpIZXBUQfMTXhfGZYNeoyZRYEiYP8w574H+KiZ7SDo+nq/mf1gsC9397vcfZm7LysvLz/xqzkOZ88t5u9WnMLjG/byg5d2pqUOIiJjLZXBsRqoNrP5ZpZDMNi9csAxK4Hrw+2PA0978Kf5SuCa8K6r+UA18LK73+rule5eFX7e0+5+XQqv4YTdcOF8Ll5czv/5+Ru8tG1/uqsjInLCUhYc4ZjFzcDjBHdAPezuG8zsy2b20fCwe4BSM9sCfA74YnjuBuBhYCPwS+Amd+9JVV1TKSvL+PpVZzOvJI8/+e5qVu9oSneVREROiGVC3/uyZcu8pqYmrXXY19LBNXe9xL7WTr53w3KWzpue1vqIiAzHzNa4+7LB9k2qwfHJrKIwxv2fPo/SeA7X3/My62oPprtKIiLHRcExjmYWBeFRlJfNdXevYn1dc7qrJCKSNAXHOJtTPI0HPn0eBbFsrrtnFW/Ut6S7SiIiSVFwpMHckjzu//S5xKIRrrt7Fa/XquUhIpOHgiNNTirN54EbzyM3msXH/uM3/HDVTj0kKCKTgoIjjeaX5fOzWy7ivIWl/K9H1/O5h1/jUFd3uqslIjIsBUealeTn8N0/OofPffBkfrq2jstv/zVb9rWmu1oiIkNScEwAWVnGLZdW8/0/OZem9i4+evuv+e+1A2dnERGZGBQcE8iF1WX8/JaLOG12IZ95cC1/86PXaGrvSne1RESOoeCYYPqe9bjpkoX89NU6Lv3XZ/lRzS4NnIvIhKHgmICyI1l84UOn8PNbLmJBeZwvPLKOq+96SWMfIjIhKDgmsMUzC/jRn53PV648g017Wrnsmy/wtcc30XFkUs73KCJThIJjgsvKMq5dPo+nPv8+PnLmbG5/ZguX/utz/HhNLT296r4SkfGn4JgkyuK5fP3qs7n/0+dSkp/D53/0Gpd983ke37BH4x8iMq4UHJPMBQvLWHnze7jzk0vp7nH+7Ptr+P07f8Nvtjamu2oikiEUHJOQmfHhM2bxxF+/l69+7Az2tnTwB/+1iuvuXsUqrTIoIimmhZymgI4jPfzgpZ3853NbaWzr4pyq6fzlJYu4+ORyzCzd1RORSWi4hZwUHFPI4a4eHq7Zxbef28ru5g6WzCrkpksWseL0mUSyFCAiMnoKjgwJjj5d3b38dG0d//nsVrY1trOgPJ8/uqCKK5dWEs+Nprt6IjIJKDgyLDj69PQ6v1hfz7ef28brdc3k50S4cmklf3j+SVTPKEh39URkAlNwZGhwJFq76yDf++0OfvZaPV09vZy3oIQ/PL+KDy6ZQXZE90iIyLEUHAqOfvvbOnmoZhc/fOlt6g4epjQ/h4+ePZuPLa3ktNmFGkwXEUDBoeAYRE+v8+ymffz4lVqe3LiPrp5eTplZwJVL53DF2XOoKIylu4oikkYKDgXHsA4e6uJ/1tXz4zW1rN11kCyD9ywq48NnzOJDp82kJD8n3VUUkXGm4FBwjNqWfW08+motP1tXz879h4hkGecvKA1DZAal8dx0V1FExoGCQ8GRNHdnw+4WHnu9nsder2dHQoh85KxZrDhtFkV52emupoikiIJDwXFC3J2N9UGI9LVEsiPG+04u5yNnzeYDp84gX8+HiEwpCg4Fx5hxd16va+Z/XtvNz9bVU9/cQSw7i/efUsHvLJnJxYvLKc7TmIjIZKfgUHCkRG+vs+btA/zPa7v5xfo9NLR2EskyzqmazgdOncEHl8zgpNL8dFdTRI6DgkPBkXK9vc66umae3LiXJ9/Yy5t7gmVuF1XEuWRxORcvrmBZ1XRyo5E011RERkPBoeAYd7uaDvGrjXt56s29vLy9iSM9Tl5OhAsWlvK+xRVcfHI5c0vy0l1NERmCgkPBkVbtnd38dut+nn1rH89uaqD2wGEA5pflc1F1GRdVl3PeghIKYrpLS2SiUHAoOCYMd2d7YzvPbmrgxS2N/Hbrfg4f6SGSZSydV8yFi8q5YFEpZ1YWqVtLJI0UHAqOCauzu4dXdh7kxS0NvLC5kdfrmnGHnGgWZ88tZnlVCcvnl7D0pOmaEl5kHCk4FByTxoH2Ll7e0cTq7U2s3tHE+t0t9PQ6WQanzirkzMpizqos4szKYk6eESeqmX1FUkLBoeCYtNo7u3n17YO8vKOJV3YeYF3tQVo6ugGIZWexZFYhp88pYmZRjPJ4LhWFfT9zKcnLIUsrH4ocl+GCI6VtfzNbAXwTiAB3u/v/G7A/F/ge8G5gP3C1u+8I990K3AD0ALe4++NmNjc8fgbgwF3u/s1UXoOkV35ulAury7iwugwIxkh27j/Ea7UHWVfbzLragzz6Sh2tnd3vODc7YpxVWcyF1WVcVF3GWZXFaqGIjIGUtTjMLAK8BXwQqAVWA9e6+8aEY/4SONPd/9zMrgF+392vNrMlwAPAcmA28CRwMlABzHL3V8ysAFgDXJH4mYNRi2PqO9zVQ0NrJw1tHexr6aShrZO6A4d5adt+1oXjJgW5Uc5bWMpF1WWcPbeYheVxTZUiMoR0tTiWA1vcfVtYiQeBy4HEf+QvB/4x3H4EuN2ClYQuBx50905gu5ltAZa7+2+BegB3bzWzN4A5Az5TMtC0nAjzSvOYV/rOZ0MOHuriN1v388LmRl7c0sCvNu7t3zeneBrVM+JUV8SprihgyexCTp1VSERdXCJDSmVwzAF2JbyvBc4d6hh37zazZqA0LH9pwLlzEk80syrgXcCqwb7czG4EbgSYN2/ecV6CTAXFeTl8+IxZfPiMWQC8vf8QG+tb2LKvlc372ti8t43fbN1PV3cvAAWxKOeEd3OdO7+E0+cUaXldkQSTsp1uZnHgx8Bn3b1lsGPc/S7gLgi6qsaxejLBHW2ZzOwv6+l13m46xGu7DrJqexOrtu/n6Tf3AZCXE+HMyiKqKwpYWJ7Pwoo4C8vjzCqKaaldyUipDI46YG7C+8qwbLBjas0sChQRDJIPea6ZZROExg/d/SepqbpkmkiWMb8sn/ll+VzxrqBx29Daycvbm3h5+37W1jbz07V1tHYcHYTPy4mwsDzOu+YV8+6TprN03nQqp09TmMiUl8rB8SjB4PilBP/orwb+wN03JBxzE3BGwuD4le5+lZmdBtzP0cHxp4BqoBe4D2hy98+Oti4aHJex4O40tHWydV87Wxva2NbQzqa9Lax9+yDtXT0AVBTk9ofIktmFVFfEKS/IVZjIpJOWwfFwzOJm4HGC23HvdfcNZvZloMbdVwL3AN8PB7+bgGvCczeY2cMEg97dwE3u3mNmFwKfAl43s7XhV/29uz+WqusQ6WNmVBTEqCiIcf7C0v7ynl5n055W1uxsYs3OA6x5+wC/WL+nf39hLEr1jAJOnhFnUUUB75pXzJlzinRrsExaegBQJAUaWjvZvLeVt/aGA/D72ti8t5UDh44AQZi8Z1EZ7z25nIuqy6icrpmCZWJJ2wOAIpmqvCCX8oJcLlhU1l/W19X18vYmnn8rmJurr2WyoCyfcxeUcOqsQk6ZWcjimQUUTdNswTIxqcUhkibuztaGNp57q5EXNjewdtdBDoYtEgieMTllZgEnzyxgQVk+C8rzmV8WZ3petsZMJOXU4hCZgMyMRRUFLKoo4IYL5+Pu7G3p5I09LbxZ38qb4c/n3mqgu/foH3hF07KZHwbJklmFnDGniCWzC7WeiYwbBYfIBGFmzCyKMbMoxiWLK/rLu3t6qT1wmO2N7WxrbGd7YxvbG9v59ZZGfvJKXXguzC/N5/Q5RZw+p5CTSvOZXTSNWcUxSvNz1EKRMaXgEJngopEsqsryqSrL55IB+xpaO1lf18zrdc2sr2umZkcTK1/bfcwxOZEsZhbFmFUUo6o0n8UzC/pfZfHc8bsQmTI0xiEyxTS1d1F74BD1zR3UHzxMfUsH9Qc7qG8+zNaGdprau/qPLc3PYfHMAmYXT2Ok6bmM4ACzoHVUkp99dCr7glzK48ENAZo4cmrQGIdIBinJz6EkP4czKwff39DayVt7W3lzTyub9rSwaW8bv97SOOxn9v196QQbPb3OgUNH6Ol95x+eBbEoc4qnBa/p05gdbi+qiHPyjAJNIDkFKDhEMkzfrcLvSbhV+Hj09joHDnWxr7UzmNK+tZN9rZ3saT5M3cHD1B3sYPWOpv6FtyAIlXefNJ1lJ01nWVUJZ88tJpatteUnGwWHiByXrCyjNJ5LaTyXU2cNfVxrxxHqDh5m4+4WVu84QM2OJp7d1AAEi22dPKOAyunTmFOcx5zpQeukcnrwKs7LGaerkWQoOEQkpQpi2ZwyM5tTZhZy5dKg/+xAexevvH2A1TsO8EZ9C1sb2nn+rUYOH+k55tzS/BwWVsRZVBGsmbKoIs6C8jjRLKOru5eunl66uns50hO8ciIRCqdFKYxlUxCLalqXFFFwiMi4m56fw6WnzuDSU2f0l7kH4ya7Dx6m9sBhdjUdYmtDMF3Lz9fV03z4yDCfOLi8nAgFsShVpfm8b3E5lyyu4JSZBbo9+QTprioRmfDcnca2Ljbva2VH4yEg6ObKiWaRE8kiJ5pFNJJFV3cvLYeP0NJxhNaO7v7tDbtb2LA7WLpnZmGMixeXc/HiCpZVTScnmkXEjEiWkWVGlgXT7Gd6uOiuKhGZ1Mzs6PxfC4/vM/a1dPDsWw08u2kfP19Xz4Ordw15bDTLWFQRDx6onF3I6XOKOHVW4TG3Gncc6aGxrZOm9i72twW3OBdOi1IQy6Ywlk3htCjTsiNTMoDU4hCRjHOkp5dXdh5gw+4Wet3p6XV63OntdXod2ru6ebO+lfV1zewPn3vpezq/u9fZ39bZvwbLcCJZxuziGOdUBcsQn1NVwvyy/EkRJmpxiIgkyI5kce6CUs5dUDrscX3zh62va2b97mberG8lNzuL0vxcSuM5lMVzKM3PpSQe3P3VcjjoImvt6Kal4wgth4+wvbGd5zY19E8PUxbP5dz5JbxrXjELyvOZV5JH5fS8SXVbsoJDRGQIifOHfWDJjJFPGEIwE3I7q3c0hcsRN/Hz1+uPOWZmYYx5pXlUTp9GYSyb/NwIefkE6mYAAAY4SURBVDlR8nMi5OVGyc+JMq8kj0UVcablpDdkFBwiIikWzIQc3E587fJ5ADS2dfJ20yHe3n+InfsPBdtN7fx2637aOrtp7+xmkAfzMSOYc2zG0TnH+sKmaNr43Ias4BARSYOyeC5l8VyWzps+6H53p7O7l0NdPbR3dtPW2c32xnY27Wll055gdcknNu4ZNFziuVEKY1Eqp+fx8J+fP+Z1V3CIiExAZkYsO0IsO0JJfjCGcuqsQj58xtHH9DuO9LB5bxt7WzpoDm89bj4cvFoOd5MdSc0gvIJDRGSSimVHOKOyiDMoGtfv1fP4IiKSFAWHiIgkRcEhIiJJUXCIiEhSFBwiIpIUBYeIiCRFwSEiIklRcIiISFIyYlp1M2sAdh7n6WVA4xhWZ7LQdWcWXXdmGc11n+Tu5YPtyIjgOBFmVjPUnPRTma47s+i6M8uJXre6qkREJCkKDhERSYqCY2R3pbsCaaLrziy67sxyQtetMQ4REUmKWhwiIpIUBYeIiCRFwTEEM1thZpvMbIuZfTHd9UklM7vXzPaZ2fqEshIz+5WZbQ5/Dr6+5SRlZnPN7Bkz22hmG8zsM2H5lL5uADOLmdnLZvZaeO3/FJbPN7NV4e/8Q2aWk+66jjUzi5jZq2b2s/D9lL9mADPbYWavm9laM6sJy477d13BMQgziwB3AJcBS4BrzWxJemuVUt8FVgwo+yLwlLtXA0+F76eSbuDz7r4EOA+4Kfz/eKpfN0An8H53Pws4G1hhZucBXwW+4e6LgAPADWmsY6p8Bngj4X0mXHOfS9z97ITnN477d13BMbjlwBZ33+buXcCDwOVprlPKuPvzQNOA4suB+8Lt+4ArxrVSKebu9e7+SrjdSvCPyRym+HUDeKAtfJsdvhx4P/BIWD7lrt3MKoHfBe4O3xtT/JpHcNy/6wqOwc0BdiW8rw3LMskMd68Pt/cAM9JZmVQysyrgXcAqMuS6wy6btcA+4FfAVuCgu3eHh0zF3/l/A/4W6A3flzL1r7mPA0+Y2RozuzEsO+7f9ehY106mHnd3M5uS922bWRz4MfBZd28J/ggNTOXrdvce4GwzKwYeBU5Jc5VSysx+D9jn7mvM7OJ01ycNLnT3OjOrAH5lZm8m7kz2d10tjsHVAXMT3leGZZlkr5nNAgh/7ktzfcacmWUThMYP3f0nYfGUv+5E7n4QeAY4Hyg2s74/Jqfa7/x7gI+a2Q6Cruf3A99kal9zP3evC3/uI/hDYTkn8Luu4BjcaqA6vOMiB7gGWJnmOo23lcD14fb1wH+nsS5jLuzfvgd4w92/nrBrSl83gJmVhy0NzGwa8EGCMZ5ngI+Hh02pa3f3W9290t2rCP57ftrdP8kUvuY+ZpZvZgV928DvAOs5gd91PTk+BDP7MEGfaAS4191vS3OVUsbMHgAuJphqeS/wJeCnwMPAPIIp6a9y94ED6JOWmV0IvAC8ztE+778nGOeYstcNYGZnEgyGRgj+eHzY3b9sZgsI/hovAV4FrnP3zvTVNDXCrqq/cfffy4RrDq/x0fBtFLjf3W8zs1KO83ddwSEiIklRV5WIiCRFwSEiIklRcIiISFIUHCIikhQFh4iIJEXBITIGzKwnnHm07zVmkyOaWVXizMUi6aYpR0TGxmF3PzvdlRAZD2pxiKRQuA7Cv4RrIbxsZovC8ioze9rM1pnZU2Y2LyyfYWaPhmtlvGZmF4QfFTGz/wrXz3gifOJbJC0UHCJjY9qArqqrE/Y1u/sZwO0EsxEA/Dtwn7ufCfwQ+FZY/i3guXCtjKXAhrC8GrjD3U8DDgIfS/H1iAxJT46LjAEza3P3+CDlOwgWTdoWTqq4x91LzawRmOXuR8LyencvM7MGoDJx2otw2vdfhQvuYGZ/B2S7+z+n/spE3kktDpHU8yG2k5E4f1IPGp+UNFJwiKTe1Qk/fxtu/4ZgllaATxJMuAjBEp5/Af2LLRWNVyVFRkt/tYiMjWnhinp9funufbfkTjezdQSthmvDsr8CvmNmXwAagD8Oyz8D3GVmNxC0LP4CqEdkAtEYh0gKhWMcy9y9Md11ERkr6qoSEZGkqMUhIiJJUYtDRESSouAQEZGkKDhERCQpCg4REUmKgkNERJLy/wGgaiZqaiqV4wAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jaTV06M9ifwV"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBTXQJgxinj_"
      },
      "source": [
        "Now that we have trained our model, we need to know how much this model will perform (in term of accuracy) on the validation set.\n",
        "\n",
        "The performance on the validation set should give us a good hint, on how well our model will perform on the test set.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtcLb9uASNo4"
      },
      "source": [
        "# Run this cell\n",
        "\n",
        "BS = 256 \n",
        "N_val = x_val.shape[0]\n",
        "\n",
        "if N_val % BS == 0:\n",
        "  n_batches = int(N_val / BS)\n",
        "else:\n",
        "  n_batches = int(N_val / BS) + 1"
      ],
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvreKsQVju9z"
      },
      "source": [
        "#### ToDo: fill in the missing lines to compute the accuracy on the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8EIkvmIwfxl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ae87d7e-8a75-473d-9258-120da4d0cde8"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "# Add the no grad context manager (covered in the tutorial)\n",
        "with torch.no_grad():\n",
        "  for batch in range(n_batches):\n",
        "    start = batch * BS\n",
        "    end = start + BS\n",
        "    \n",
        "    val_images = x_val[start:end]\n",
        "    val_labels = y_val[start:end]\n",
        "    \n",
        "    val_images =  val_images.to(device = device)        # change the device of val_images to gpu\n",
        "    val_labels =  val_labels.to(device = device)      # change the device of val_labels to gpu\n",
        "    \n",
        "    \n",
        "    outputs =  model(val_images)         # feed the val_images to the model to get the outputs\n",
        "    #outputs = Tensor.cpu()\n",
        "\n",
        "    predicted = torch.argmax(outputs, 1)        # compute the argmax of the outputs to get the predicted labels\n",
        "    \n",
        "    total += val_labels.size(0)\n",
        "    \n",
        "    correct += (predicted == val_labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the %d test images: %d %%' % (\n",
        "    total, 100 * correct / total))"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 88 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O89dx5apqnal"
      },
      "source": [
        "# You are expected to get good val acc > 70% at least"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPzjRtH6qtrg"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    }
  ]
}